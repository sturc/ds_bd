{"cells":[{"source":["# WordCount for Yarn"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputFile = \"hdfs:///data/ghEmployees.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputFile = \"hdfs:///tmp/jwcsturm.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#create a SparkSession without local master and app name\n","spark = (SparkSession\n","       .builder \n","       .master(\"yarn\") \n","       .appName(\"WordCount\")\n","       .getOrCreate())\n","# read file \n","spark.sparkContext.setLogLevel(\"ERROR\")\n","input = spark.sparkContext.textFile(inputFile)\n","counts = input.flatMap(lambda line : line.split(\" \")).map(lambda word : [word, 1]).reduceByKey(lambda a, b : a + b)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# write the result to hdfs\n","counts.saveAsTextFile(outputFile)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(counts.collect())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spark.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}