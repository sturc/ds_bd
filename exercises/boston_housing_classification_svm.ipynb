{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Boston Housing Classification SVM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql.types import BooleanType\n","from pyspark.ml.feature import StringIndexer, VectorAssembler\n","from pyspark.ml.classification import LinearSVC\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql.functions import expr\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from helpers.helper_functions import translate_to_file_string"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputFile = translate_to_file_string(\"../data/Boston_Housing_Data.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Spark session creation "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spark = (SparkSession\n","       .builder\n","       .appName(\"BostonHousingClassSVN\")\n","       .getOrCreate())"]},{"cell_type":"markdown","metadata":{},"source":["DataFrame creation using an ifered Schema "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile) \\\n","       .withColumn(\"CATBOOL\", expr(\"CAT\").cast(BooleanType()))\n","print(df.printSchema())"]},{"cell_type":"markdown","metadata":{},"source":["Prepare training and test data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["featureCols = df.columns.copy()\n","featureCols.remove(\"MEDV\")\n","featureCols.remove(\"CAT\")\n","featureCols.remove(\"CATBOOL\") \n","print(featureCols)\n","\n","assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labledPointDataSet = assembler.transform(df)\n","splits = labledPointDataSet.randomSplit([0.9, 0.1 ], 12345)\n","training = splits[0]\n","test = splits[1]"]},{"cell_type":"markdown","metadata":{},"source":["Support Vector Machine Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO Optimize different setting\n","lsvc = LinearSVC(labelCol=\"CAT\", featuresCol=\"features\",maxIter=10\n","                    ,regParam=0.5, standardization=True ) "]},{"cell_type":"markdown","metadata":{},"source":["Train the model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lsvcModel = lsvc.fit(training)"]},{"cell_type":"markdown","metadata":{},"source":["Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = lsvcModel.transform(test)\n","predictions.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = BinaryClassificationEvaluator(labelCol=\"CAT\",rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error\",(1.0 - accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["countcorrect = predictions.filter(\"CAT == prediction\").count()\n","countall = predictions.count()\n","accuracy = countcorrect/countall\n","print(f\"countcorrect: {countcorrect}\")\n","print(f\"countall: {countall}\")\n","print(f\"accuracy: {accuracy}\")\n","print(f\"Test Error {1.0-accuracy}\")"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}