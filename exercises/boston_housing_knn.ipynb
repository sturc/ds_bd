{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Boston Housing KNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pyspark.sql.types import BooleanType\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, BucketedRandomProjectionLSH, MinHashLSH\n","from pyspark.ml.classification import LinearSVC\n","from pyspark.sql.session import SparkSession, Row\n","from pyspark.sql.functions import desc, expr\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from helpers.helper_functions import translate_to_file_string"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputFile = translate_to_file_string(\"../data/Boston_Housing_Data.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Spark session creation "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spark = (SparkSession\n","       .builder\n","       .appName(\"BostonHousingKNN\")\n","       .getOrCreate())"]},{"cell_type":"markdown","metadata":{},"source":["DataFrame creation using an ifered Schema "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile) \\\n","       .withColumn(\"CATBOOL\", expr(\"CAT\").cast(BooleanType()))\n","print(df.printSchema())"]},{"cell_type":"markdown","metadata":{},"source":["Prepare training and test data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["featureCols = df.columns.copy()\n","featureCols.remove(\"MEDV\")\n","featureCols.remove(\"CAT\")\n","featureCols.remove(\"CATBOOL\") \n","print(featureCols)\n","\n","assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labledPointDataSet = assembler.transform(df)\n","splits = labledPointDataSet.randomSplit([0.9, 0.1 ], 12345)\n","training = splits[0]\n","test = splits[1]"]},{"cell_type":"markdown","metadata":{},"source":["LHS Euclidean Distance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO optimize the params to minimize the test error\n","# TODO try the MinHashLSH too\n","lhsED = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength =2.0, numHashTables=3)"]},{"cell_type":"markdown","metadata":{},"source":["Train the model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["modelED = lhsED.fit(training)"]},{"cell_type":"markdown","metadata":{},"source":["Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resultList = []\n","# The Nearest neighbor testing\n","# TODO add other aggregation methods \n","for row in test.collect() :\n","     neighbors = modelED.approxNearestNeighbors(training, row.features, 5)\n","     grouped = neighbors.groupBy(df.CAT).count()\n","     if grouped.count() > 0 :\n","          result = grouped.orderBy(desc(\"count\")).first().CAT\n","          newRow = Row(CAT=row.CAT, features=row.features, prediction=float                    (result))\n","          resultList.append(newRow)\t\n","\n","predictions = spark.createDataFrame(resultList)\n","predictions.createOrReplaceTempView(\"resultList\")\n","predictions.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluator = BinaryClassificationEvaluator(labelCol=\"CAT\",rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error\",(1.0 - accuracy))"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}